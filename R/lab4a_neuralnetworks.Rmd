---
title: "Lab4a_2.1_neuralnetworks"
author: "Julia Parish"
date: "2/26/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 1 Overview
In this lab, you’ll become introduced to Deep Learning techniques that enable you to classify complex input data, such as imagery or sound. Eventually you’ll use a subset of the dataset from iNat Challenge 2021 - FGVC8 | Kaggle to apply Deep Learning techniques to classify species from images. 


# 2.1 R
## 2.1.1 Install Python for R

```{r}
# load libraries
librarian::shelf(
  devtools,
  keras,
  reticulate,
  tensorflow)

# show library versions and paths
session_info() 

# install Python into user space
(reticulate::miniconda_path()) # show the Python path
if (!file.exists(reticulate::miniconda_path()))
  reticulate::install_miniconda()

# install keras with tensorflow
if (!keras::is_keras_available())
  keras::install_keras()

```


The MNIST dataset comes preloaded in Keras, in the form of train and test lists, each of which includes a set of images (x) and associated labels (y):

## 2.1.2 Listing 2.1 Loading the MNIST dataset in Keras

```{r}

library(keras)
mnist <- dataset_mnist()
```

The train_images and train_labels form the training set, the data that the model will learn from. The model will then be tested on the test set, test_images and test_labels. The images are encoded as 3D arrays, and the labels are a 1D array of digits, ranging from 0 to 9. There is a one-to-one correspondence between the images and the labels.
```{r}
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images  <- mnist$test$x
test_labels  <- mnist$test$y
```

```{r}
# The R str() function is a convenient way to get a quick glimpse at the structure of an array. 

str(train_images)

str(train_labels)
```

## Let’s have a look at the test data:

```{r}
str(test_images)

str(test_labels)

```

```{r}
librarian::shelf(glue)

dim(train_images)

dim(train_labels)

par(mfrow=c(2,2))
sapply(
  1:4, function(i){ # i = 5
    plot(
      as.raster(train_images[i,,]/255),
      main = glue("image_{i}: label = {train_labels[i]}")) })
```

## 2.1.3 Listing 2.2 The network architecture

```{r}
#You may alternatively see messages about missing cuda or some nvidia driver doesn’t exist. That again is because we only have a CPU and not GPU setup on Taylor. Nvidia is the GPU manufacturer who made the CUDA language to interface with the GPU that most dedicated deep learning systems use.

network <- keras_model_sequential() %>% 
  layer_dense(units = 512, activation = "relu", input_shape = c(28 * 28)) %>% 
  layer_dense(units = 10, activation = "softmax")
```

## 2.1.4 Listing 2.3 The compilation step

Before training, we’ll preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the [0, 1] interval. Previously, our training images, for instance, were stored in an array of shape (60000, 28, 28) of type integer with values in the [0, 255] interval. We transform it into a double array of shape (60000, 28 * 28) with values between 0 and 1.

```{r}
network %>% compile(
  optimizer = "rmsprop",
  loss      = "categorical_crossentropy",
  metrics   = c("accuracy"))
```

## 2.1.5 Listing 2.4 Preparing the image data

```{r}
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255
test_images  <- array_reshape(test_images, c(10000, 28 * 28))
test_images  <- test_images / 255
```

We are now ready to train our network, which in Keras is done via a call to the fit method of the network: we “fit” the model to its training data.

```{r}
network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)
```


